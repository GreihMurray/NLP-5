{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhJKelz22XKMwGt3DZPB6i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreihMurray/NLP-5/blob/master/Copy_of_anything_goes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbsVlxPxKnHT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, GRU, Embedding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from math import log2\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEtePjF8K85C",
        "outputId": "aa3762ea-ecee-4eaf-9323-0bc5d498f1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heavily based on https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7"
      ],
      "metadata": {
        "id": "Ljp9_IHfenhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sents(data):\n",
        "    split_data = []\n",
        "\n",
        "    for row in tqdm(data, desc='splitting data'):\n",
        "        split_data.append(row.split(' '))\n",
        "\n",
        "    return split_data"
      ],
      "metadata": {
        "id": "lV45PxernhkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(grams, raw_data, loader=False):\n",
        "    chars = sorted(list(set(raw_data)))\n",
        "    chars.append('<UNK>')\n",
        "    mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "    if loader == True:\n",
        "        with open('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/encode.json') as infile:\n",
        "          mapping = json.load(infile) \n",
        "\n",
        "    sequences = list()\n",
        "    for line in tqdm(grams, desc='Encoding'):\n",
        "        # integer encode line\n",
        "        try:\n",
        "          encoded_seq = [mapping[char] for char in line]\n",
        "        except KeyError:\n",
        "          encoded_seq = [mapping['<UNK>'] for char in line]\n",
        "        # store\n",
        "        sequences.append(encoded_seq)\n",
        "    return sequences, mapping"
      ],
      "metadata": {
        "id": "3hU8ifQOKsZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7"
      ],
      "metadata": {
        "id": "B9gsORg7ergF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab, 20, input_length=GRAMS-1, trainable=True))\n",
        "    model.add(GRU(75, recurrent_dropout=0.1, dropout=0.1))\n",
        "    model.add(Dense(vocab, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4MffHLMrKtsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "original"
      ],
      "metadata": {
        "id": "MxE5hjPTetSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_train_file(file_name):\n",
        "    all_data = []\n",
        "    descript = 'Reading ' + file_name\n",
        "\n",
        "    f = open(file_name, 'r', encoding='utf-8')\n",
        "    full_text = f.read()\n",
        "\n",
        "    cur_sent = []\n",
        "\n",
        "    for line in tqdm(full_text.split('\\n'), desc=descript):\n",
        "        if line == '<s>':\n",
        "            cur_sent = []\n",
        "            continue\n",
        "        if line in '()':\n",
        "            continue\n",
        "        if line == '</s>':\n",
        "            if len(cur_sent) <= 50:\n",
        "              all_data.append(cur_sent)\n",
        "            continue\n",
        "        else:\n",
        "            cur_sent.append(line.lower())\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "cOiW3aNoK1Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_lang_train(source_file, targ_file):\n",
        "    all_data = []\n",
        "    descript = 'Reading files'\n",
        "    clean_punct = '-.,\\''\n",
        "\n",
        "    source_data = read_train_file(source_file)\n",
        "    target_data = read_train_file(targ_file)\n",
        "\n",
        "    for i in tqdm(range(0, len(source_data)), desc='Cleaning data'):\n",
        "        clean_sentence = '<OGA> ' + ' '.join(source_data[i]) + ' <NGA> ' + ' '.join(target_data[i])\n",
        "\n",
        "        all_data.append(clean_sentence)\n",
        "\n",
        "    data = ' '.join(all_data[:int(len(all_data) * 0.8)])\n",
        "    hold_out = ' '.join(all_data[int(len(all_data) * 0.8):])\n",
        "\n",
        "    return data, hold_out"
      ],
      "metadata": {
        "id": "c-VBYC8se7qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "original"
      ],
      "metadata": {
        "id": "8n6xm5Ezeuqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_test_data(file_name):\n",
        "    all_data = []\n",
        "    descript = 'Reading files'\n",
        "    clean_punct = '-.,\\''\n",
        "\n",
        "    source_data = read_train_file(file_name)\n",
        "\n",
        "    for i in tqdm(range(0, len(source_data)), desc='Cleaning data'):\n",
        "        clean_sentence = '<OGA> ' + ' '.join(source_data[i]) + ' <NGA> '\n",
        "\n",
        "        all_data.append(clean_sentence)\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "2bjtzkHoYPrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "original"
      ],
      "metadata": {
        "id": "zLqVB0kgev92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_n_grams(data, n=3):\n",
        "    descript = \"Generating \" + str(n) + \" Grams:\"\n",
        "\n",
        "    n_grams = [''.join(data[i:i+n]) for i in tqdm(range(len(data) - n + 1), desc=descript)]\n",
        "\n",
        "    return n_grams"
      ],
      "metadata": {
        "id": "0iqsefDGK40y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def gen_n_grams(data, n=3):\n",
        "#     descript = \"Generating and counting \" + str(n) + \" Grams:\"\n",
        "#     counts = {}\n",
        "#     n_grams = []\n",
        "\n",
        "#     for row in tqdm(data, desc=descript):\n",
        "#         row = row.split(' ')\n",
        "#         gram_list = [' '.join(row[i:i+n]) for i in range(len(row) - n + 1)]\n",
        "        \n",
        "#         for gram in gram_list:\n",
        "#           if gram in counts.keys():\n",
        "#             counts[gram] += 1\n",
        "#           else:\n",
        "#             counts[gram] = 1\n",
        "\n",
        "#     #n_grams = [''.join(data[i:i+n]) for i in tqdm(range(len(data) - n + 1), desc=descript)]\n",
        "\n",
        "#     return counts"
      ],
      "metadata": {
        "id": "J5SgDULclYrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    data, hold_out = read_lang_train('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-source.txt', '/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-target.txt')\n",
        "    \n",
        "    data = data[:int(len(data) * 0.5)]\n",
        "\n",
        "    n_grams = gen_n_grams(data, GRAMS)\n",
        "\n",
        "    n_grams, mapping = encode(n_grams, data)\n",
        "\n",
        "    print(mapping)\n",
        "\n",
        "    with open('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/encode.json', \"w\") as outfile:\n",
        "      json.dump(mapping, outfile)\n",
        "\n",
        "  # Below code from https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "    vocab = len(mapping)\n",
        "    sequences = np.array(n_grams)\n",
        "\n",
        "    print(vocab)\n",
        "\n",
        "    # create X and y\n",
        "    x, y = sequences[:, :-1], sequences[:, -1]\n",
        "    # one hot encode y\n",
        "    y = to_categorical(y, num_classes=vocab)\n",
        "    # create train and validation sets\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "    print('Train shape:', x_tr.shape, 'Val shape:', x_val.shape)\n",
        "\n",
        "    model = build_model(vocab)\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "  # Original addition\n",
        "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "    model.fit(x_tr, y_tr, epochs=4, verbose=1, validation_data=(x_val, y_val), callbacks=stop_early, batch_size=125)\n",
        "    model.save('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/lang_model')\n"
      ],
      "metadata": {
        "id": "T_2m3XwmKwSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRAMS = 10"
      ],
      "metadata": {
        "id": "wmxZN9ZdLO5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMsCOFTvKzFn",
        "outputId": "17247cbf-a1c4-4066-8f97-77010693e292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading /content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-source.txt: 100%|██████████| 925535/925535 [00:00<00:00, 1581813.17it/s]\n",
            "Reading /content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-target.txt: 100%|██████████| 910805/910805 [00:00<00:00, 1610360.19it/s]\n",
            "Cleaning data: 100%|██████████| 44544/44544 [00:00<00:00, 433275.69it/s]\n",
            "Generating 10 Grams:: 100%|██████████| 3357516/3357516 [00:03<00:00, 1048334.64it/s]\n",
            "Encoding: 100%|██████████| 3357516/3357516 [00:10<00:00, 335307.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, \"'\": 3, ',': 4, '-': 5, '.': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '9': 15, ':': 16, ';': 17, '<': 18, '>': 19, '?': 20, 'A': 21, 'G': 22, 'N': 23, 'O': 24, '[': 25, ']': 26, '^': 27, '_': 28, '`': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55, '£': 56, '«': 57, '»': 58, 'á': 59, 'ã': 60, 'é': 61, 'í': 62, 'ó': 63, 'õ': 64, 'ú': 65, '‑': 66, '—': 67, '‘': 68, '’': 69, '“': 70, '”': 71, '…': 72, '<UNK>': 73}\n",
            "74\n",
            "Train shape: (3021764, 9) Val shape: (335752, 9)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 9, 20)             1480      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 75)                21825     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 74)                5624      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,929\n",
            "Trainable params: 28,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/4\n",
            "24175/24175 [==============================] - 495s 20ms/step - loss: 1.6299 - acc: 0.5037 - val_loss: 1.4341 - val_acc: 0.5609\n",
            "Epoch 2/4\n",
            "24175/24175 [==============================] - 487s 20ms/step - loss: 1.4803 - acc: 0.5448 - val_loss: 1.3908 - val_acc: 0.5722\n",
            "Epoch 3/4\n",
            "24175/24175 [==============================] - 492s 20ms/step - loss: 1.4540 - acc: 0.5523 - val_loss: 1.3649 - val_acc: 0.5803\n",
            "Epoch 4/4\n",
            "24175/24175 [==============================] - 489s 20ms/step - loss: 1.4403 - acc: 0.5562 - val_loss: 1.3534 - val_acc: 0.5828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "Hi9nNZNoe4GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_entropy(preds, mapping, sequences, vocab):\n",
        "    entropy = 0\n",
        "\n",
        "    count = 0\n",
        "    pred_len = len(preds)\n",
        "\n",
        "    keys = sequences[:, -1]\n",
        "\n",
        "    for i in range(0, len(sequences)):\n",
        "      entropy -= (1/(pred_len)) * log2(preds[i][keys[i]])\n",
        "\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "FdaJ8Y9nb4lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "qe4vrjL5e5hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_my_model():\n",
        "    model = keras.models.load_model('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/lang_model')\n",
        "\n",
        "    data = read_test_data('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-source.txt')\n",
        "\n",
        "    n_grams = gen_n_grams(data, GRAMS)\n",
        "    clean = n_grams\n",
        "    n_grams, mapping = encode(n_grams, data, loader=True)\n",
        "\n",
        "    vocab = len(mapping)\n",
        "    sequences = np.array(n_grams)\n",
        "\n",
        "    print(se)\n",
        "\n",
        "    seqs = sequences[:,:-1]\n",
        "\n",
        "    preds = model.predict(seqs)\n",
        "    print(preds[:5])\n",
        "\n",
        "    entropy = calc_entropy(preds, mapping, sequences, vocab)\n",
        "    print('\\n', entropy)\n",
        "    "
      ],
      "metadata": {
        "id": "n2e5zjJbX4Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_my_model()"
      ],
      "metadata": {
        "id": "RWVPdo1DZaHx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "4948426b-8e77-4d9e-833a-4d7a248d6def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading /content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-source.txt: 100%|██████████| 925535/925535 [00:03<00:00, 288219.05it/s]\n",
            "Cleaning data: 100%|██████████| 44544/44544 [00:00<00:00, 644154.02it/s]\n",
            "Generating 10 Grams:: 100%|██████████| 44535/44535 [00:00<00:00, 648011.94it/s]\n",
            "Encoding: 100%|██████████| 44535/44535 [00:03<00:00, 11354.02it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-139f4111eb9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_my_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-87a0a4d114bd>\u001b[0m in \u001b[0;36mload_my_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_grams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of models & Performance (KWERE) (12 grams)\n",
        "  # act_model - 1.235 entropy (Batch size 250)\n",
        "  # act_model500 - 1.282 entropy (Batch size 500)\n",
        "  # act_model125 - 1.233 entropy (Batch size 125)\n",
        "  # act_model50 - 1.201 entropy (Batch size 50)"
      ],
      "metadata": {
        "id": "4UudaUAbfQDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of models & Performance (SWAHILI) (6 grams)\n",
        "  # act_model - \n",
        "  # sw_act_model500 - 1.474 entropy (Batch size 500)\n",
        "  # act_model125 - \n",
        "  # act_model50 - "
      ],
      "metadata": {
        "id": "r-E11F-apqby"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}