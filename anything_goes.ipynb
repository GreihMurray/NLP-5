{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOlWW2ziBQc3eBrP742LbFt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreihMurray/NLP-5/blob/master/anything_goes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dELP-OkqOAGG"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import helper\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from keras.layers import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-32r4adZOG6N",
        "outputId": "7ecdfaf3-791b-4450-f323-6ba4b125bd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "3a0FcwKfVnRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_train_file(file_name):\n",
        "    all_data = []\n",
        "    descript = 'Reading ' + file_name\n",
        "\n",
        "    f = open(file_name, 'r', encoding='utf-8')\n",
        "    full_text = f.read()\n",
        "\n",
        "    cur_sent = []\n",
        "\n",
        "    for line in tqdm(full_text.split('\\n'), desc=descript):\n",
        "        if line == '<s>':\n",
        "            cur_sent = []\n",
        "            continue\n",
        "        if line in '()':\n",
        "            continue\n",
        "        if line == '</s>':\n",
        "            all_data.append(cur_sent)\n",
        "            continue\n",
        "        else:\n",
        "            cur_sent.append(line.lower())\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "OOd6ki5qONYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "9rTRpgB4Voiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = read_train_file('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-source.txt')\n",
        "target = read_train_file('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-target.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2l6QuahOQdT",
        "outputId": "46c633cf-8adf-4259-bf82-558842991061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading /content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-source.txt: 100%|██████████| 925535/925535 [00:00<00:00, 2058536.17it/s]\n",
            "Reading /content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/train-target.txt: 100%|██████████| 910805/910805 [00:00<00:00, 1433167.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "HvYXSj2WVW33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_counter = collections.Counter([word for sentence in source for word in sentence])\n",
        "target_counter = collections.Counter([word for sentence in target for word in sentence])\n",
        "\n",
        "print('{} Source words.'.format(len([word for sentence in source for word in sentence])))\n",
        "print('{} unique source words.'.format(len(source_counter)))\n",
        "print('10 Most common words in the source dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*source_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} Target words.'.format(len([word for sentence in target for word in sentence])))\n",
        "print('{} unique target words.'.format(len(target_counter)))\n",
        "print('10 Most common words in the target dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*target_counter.most_common(10)))[0]) + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIjncfeGO_nc",
        "outputId": "26394e62-8edf-491c-821d-5b9b556d37b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "834933 Source words.\n",
            "31035 unique source words.\n",
            "10 Most common words in the source dataset:\n",
            "\".\" \"a\" \"an\" \",\" \"agus\" \"ar\" \"\"\" \"bhí\" \"na\" \"sé\"\n",
            "\n",
            "820239 Target words.\n",
            "25735 unique target words.\n",
            "10 Most common words in the target dataset:\n",
            "\".\" \"a\" \"an\" \",\" \"agus\" \"ar\" \"bhí\" \"\"\" \"ag\" \"sé\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "_ibEDklOVZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x):\n",
        "    \"\"\"\n",
        "    Tokenize x\n",
        "    :param x: List of sentences/strings to be tokenized\n",
        "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    x_tk = Tokenizer(char_level = False)\n",
        "    x_tk.fit_on_texts(x)\n",
        "    return x_tk.texts_to_sequences(x), x_tk"
      ],
      "metadata": {
        "id": "u4p7Y7itQdzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "hI7E3b9wVbCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(x, length=None):\n",
        "    \"\"\"\n",
        "    Pad x\n",
        "    :param x: List of sequences.\n",
        "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
        "    :return: Padded numpy array of sequences\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    if length is None:\n",
        "        length = max([len(sentence) for sentence in x])\n",
        "    return pad_sequences(x, maxlen = length, padding = 'post')"
      ],
      "metadata": {
        "id": "ZdSBtM3qQmYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "6EkdpDOVVbm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(x, y):\n",
        "    \"\"\"\n",
        "    Preprocess x and y\n",
        "    :param x: Feature List of sentences\n",
        "    :param y: Label List of sentences\n",
        "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
        "    \"\"\"\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk"
      ],
      "metadata": {
        "id": "VArK1XP6RAp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "Qe26v-1yVcLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_source, pre_target, source_token, target_token =\\\n",
        "    preprocess(source, target)\n",
        "    \n",
        "max_source_length = pre_source.shape[1]\n",
        "max_target_length = pre_target.shape[1]\n",
        "source_vocab_size = len(source_token.word_index)\n",
        "target_vocab_size = len(target_token.word_index)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max source sentence length:\", max_source_length)\n",
        "print(\"Max target sentence length:\", max_target_length)\n",
        "print(\"Source vocabulary size:\", source_vocab_size)\n",
        "print(\"Target vocabulary size:\", target_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O76rRuGfRDkB",
        "outputId": "78abe4c7-2cf0-446e-878e-1cb8a7f240dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preprocessed\n",
            "Max source sentence length: 231\n",
            "Max target sentence length: 221\n",
            "Source vocabulary size: 31035\n",
            "Target vocabulary size: 25735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "ql5ztpOMVdEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "metadata": {
        "id": "uectedE5Rl-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "4ZJW6EqoVdsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    # TODO: Build the layers\n",
        "    learning_rate = 1e-3\n",
        "    input_seq = Input(input_shape[1:])\n",
        "    rnn = GRU(64, return_sequences = True)(input_seq)\n",
        "    logits = TimeDistributed(Dense(french_vocab_size))(rnn)\n",
        "    model = Model(input_seq, Activation('softmax')(logits))\n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(learning_rate), \n",
        "                 metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "kbhrzYZhRpaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "cW-1oaa4Veh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    # TODO: Implement\n",
        "    learning_rate = 1e-3\n",
        "    rnn = GRU(64, return_sequences=True, activation=\"tanh\")\n",
        "    \n",
        "    embedding = Embedding(french_vocab_size, 64, input_length=input_shape[1]) \n",
        "    logits = TimeDistributed(Dense(french_vocab_size, activation=\"softmax\"))\n",
        "    \n",
        "    model = Sequential()\n",
        "    #em can only be used in first layer --> Keras Documentation\n",
        "    model.add(embedding)\n",
        "    model.add(rnn)\n",
        "    model.add(logits)\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "o9Smn9e1SQq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "Sgt94ZksVfXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a bidirectional RNN model on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    learning_rate = 1e-3\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(128, return_sequences = True, dropout = 0.1), \n",
        "                           input_shape = input_shape[1:]))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(learning_rate), \n",
        "                 metrics = ['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "YykUEHtVT73W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "xO8H1BkVVf-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train an encoder-decoder model on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # OPTIONAL: Implement\n",
        "    learning_rate = 1e-3\n",
        "    model = Sequential()\n",
        "    model.add(GRU(128, input_shape = input_shape[1:], return_sequences = False))\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    model.add(GRU(128, return_sequences = True))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n",
        "    \n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(learning_rate), \n",
        "                 metrics = ['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "JCRiMeUBUbGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "FLsddfN-Vgmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=english_vocab_size,output_dim=128,input_length=input_shape[1]))\n",
        "    model.add(Bidirectional(GRU(256,return_sequences=False)))\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    model.add(Bidirectional(GRU(256,return_sequences=True)))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size,activation='softmax')))\n",
        "    learning_rate = 0.005\n",
        "    \n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(learning_rate), \n",
        "                 metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "V4w8O1OrUuZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "vu1czV2sVhPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Simple RNN\n",
        "\n",
        "tmp_x = pad(pre_source, max_target_length)\n",
        "tmp_x = tmp_x.reshape((-1, pre_target.shape[-2], 1))\n",
        "\n",
        "# Train the neural network\n",
        "simple_rnn_model = simple_model(\n",
        "    tmp_x.shape,\n",
        "    max_target_length,\n",
        "    source_vocab_size,\n",
        "    target_vocab_size)\n",
        "simple_rnn_model.fit(tmp_x, pre_target, batch_size=32, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Print prediction(s)\n",
        "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], target_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og6qGFFMRsEV",
        "outputId": "7dca5300-44e4-4cbf-fd6e-4397c349d3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1130/1130 [==============================] - 161s 141ms/step - loss: 0.9704 - accuracy: 0.9192 - val_loss: nan - val_accuracy: 0.9287\n",
            "Epoch 2/10\n",
            "1130/1130 [==============================] - 163s 144ms/step - loss: 0.5466 - accuracy: 0.9205 - val_loss: nan - val_accuracy: 0.9290\n",
            "Epoch 3/10\n",
            "1130/1130 [==============================] - 163s 144ms/step - loss: 0.5401 - accuracy: 0.9207 - val_loss: nan - val_accuracy: 0.9290\n",
            "Epoch 4/10\n",
            "1130/1130 [==============================] - 162s 144ms/step - loss: 0.5366 - accuracy: 0.9209 - val_loss: nan - val_accuracy: 0.9291\n",
            "Epoch 5/10\n",
            "1130/1130 [==============================] - 162s 144ms/step - loss: 0.5340 - accuracy: 0.9210 - val_loss: nan - val_accuracy: 0.9291\n",
            "Epoch 6/10\n",
            "1130/1130 [==============================] - 162s 144ms/step - loss: 0.5317 - accuracy: 0.9211 - val_loss: nan - val_accuracy: 0.9291\n",
            "Epoch 7/10\n",
            "1130/1130 [==============================] - 162s 144ms/step - loss: 0.5298 - accuracy: 0.9210 - val_loss: nan - val_accuracy: 0.9293\n",
            "Epoch 8/10\n",
            "1130/1130 [==============================] - 162s 144ms/step - loss: 0.5276 - accuracy: 0.9212 - val_loss: nan - val_accuracy: 0.9293\n",
            "Epoch 9/10\n",
            "1130/1130 [==============================] - 162s 144ms/step - loss: 0.5255 - accuracy: 0.9212 - val_loss: nan - val_accuracy: 0.9294\n",
            "Epoch 10/10\n",
            "1130/1130 [==============================] - 162s 144ms/step - loss: 0.5237 - accuracy: 0.9213 - val_loss: nan - val_accuracy: 0.9294\n",
            "1/1 [==============================] - 0s 317ms/step\n",
            "bhí an a a a , , , , , a an arsa . .                                                                                                                                                                                                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "-zaZoe2SVrRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rnn_model.save('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/simple_rnn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qlys_BLdXy7D",
        "outputId": "2c49ef08-eb96-46a0-e510-98d49ce1e8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "P2NiTZsjViYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train bi-directional\n",
        "\n",
        "tmp_x = pad(pre_source, pre_target.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, pre_target.shape[-2], 1))\n",
        "\n",
        "bidi_model = bd_model(\n",
        "    tmp_x.shape,\n",
        "    pre_target.shape[1],\n",
        "    len(source_token.word_index)+1,\n",
        "    len(target_token.word_index)+1)\n",
        "\n",
        "\n",
        "bidi_model.fit(tmp_x, pre_target, batch_size=32, epochs=20, validation_split=0.2)\n",
        "\n",
        "# Print prediction(s)\n",
        "print(logits_to_text(bidi_model.predict(tmp_x[:1])[0], target_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bVU1i2qT-T8",
        "outputId": "336ce0df-4a88-4beb-cae6-7a814abeba12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1130/1130 [==============================] - 335s 294ms/step - loss: 0.7390 - accuracy: 0.9194 - val_loss: 0.4859 - val_accuracy: 0.9286\n",
            "Epoch 2/20\n",
            "1130/1130 [==============================] - 332s 294ms/step - loss: 0.5451 - accuracy: 0.9205 - val_loss: 0.4838 - val_accuracy: 0.9291\n",
            "Epoch 3/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.5402 - accuracy: 0.9207 - val_loss: 0.4811 - val_accuracy: 0.9293\n",
            "Epoch 4/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.5340 - accuracy: 0.9211 - val_loss: 0.4775 - val_accuracy: 0.9297\n",
            "Epoch 5/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.5272 - accuracy: 0.9216 - val_loss: 0.4751 - val_accuracy: 0.9296\n",
            "Epoch 6/20\n",
            "1130/1130 [==============================] - 333s 295ms/step - loss: 0.5210 - accuracy: 0.9219 - val_loss: 0.4719 - val_accuracy: 0.9302\n",
            "Epoch 7/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.5146 - accuracy: 0.9223 - val_loss: 0.4697 - val_accuracy: 0.9303\n",
            "Epoch 8/20\n",
            "1130/1130 [==============================] - 333s 295ms/step - loss: 0.5086 - accuracy: 0.9226 - val_loss: 0.4690 - val_accuracy: 0.9305\n",
            "Epoch 9/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.5032 - accuracy: 0.9228 - val_loss: 0.4689 - val_accuracy: 0.9304\n",
            "Epoch 10/20\n",
            "1130/1130 [==============================] - 333s 295ms/step - loss: 0.4983 - accuracy: 0.9229 - val_loss: 0.4690 - val_accuracy: 0.9306\n",
            "Epoch 11/20\n",
            "1130/1130 [==============================] - 333s 295ms/step - loss: 0.4936 - accuracy: 0.9230 - val_loss: 0.4683 - val_accuracy: 0.9306\n",
            "Epoch 12/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.4892 - accuracy: 0.9232 - val_loss: 0.4693 - val_accuracy: 0.9307\n",
            "Epoch 13/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.4851 - accuracy: 0.9233 - val_loss: 0.4694 - val_accuracy: 0.9308\n",
            "Epoch 14/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.4814 - accuracy: 0.9233 - val_loss: 0.4698 - val_accuracy: 0.9307\n",
            "Epoch 15/20\n",
            "1130/1130 [==============================] - 333s 295ms/step - loss: 0.4779 - accuracy: 0.9235 - val_loss: 0.4703 - val_accuracy: 0.9310\n",
            "Epoch 16/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.4744 - accuracy: 0.9236 - val_loss: 0.4710 - val_accuracy: 0.9307\n",
            "Epoch 17/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.4711 - accuracy: 0.9237 - val_loss: 0.4715 - val_accuracy: 0.9309\n",
            "Epoch 18/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.4682 - accuracy: 0.9239 - val_loss: 0.4716 - val_accuracy: 0.9309\n",
            "Epoch 19/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.4653 - accuracy: 0.9240 - val_loss: 0.4729 - val_accuracy: 0.9309\n",
            "Epoch 20/20\n",
            "1130/1130 [==============================] - 333s 294ms/step - loss: 0.4625 - accuracy: 0.9242 - val_loss: 0.4733 - val_accuracy: 0.9309\n",
            "1/1 [==============================] - 1s 521ms/step\n",
            "bhí an an an an an an an an an an an an . .                                                                                                                                                                                                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "iqt9ikxBVsnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bidi_model.save('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/bidirection')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX3p4UfZYlRU",
        "outputId": "2a31171d-abef-439b-ce61-6c59f87928fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "tBSS24phVjVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train embedding model\n",
        "\n",
        "tmp_x = pad(pre_source, max_target_length)\n",
        "tmp_x = tmp_x.reshape((-1, pre_target.shape[-2]))\n",
        "\n",
        "# TODO: Train the neural network\n",
        "\n",
        "embeded_model = embed_model(\n",
        "    tmp_x.shape,\n",
        "    max_target_length,\n",
        "    source_vocab_size,\n",
        "    target_vocab_size)\n",
        "\n",
        "embeded_model.fit(tmp_x, pre_target, batch_size=32, epochs=10, validation_split=0.2)\n",
        "\n",
        "\n",
        "# TODO: Print prediction(s)\n",
        "print(logits_to_text(embeded_model.predict(tmp_x[:1])[0], target_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoSkaoMITRO7",
        "outputId": "d78151db-ae15-4c94-bffd-3c8b3b773fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1130/1130 [==============================] - 270s 234ms/step - loss: 0.9987 - accuracy: 0.9153 - val_loss: nan - val_accuracy: 0.9280\n",
            "Epoch 2/10\n",
            "1130/1130 [==============================] - 265s 234ms/step - loss: 0.5450 - accuracy: 0.9201 - val_loss: nan - val_accuracy: 0.9294\n",
            "Epoch 3/10\n",
            "1130/1130 [==============================] - 265s 235ms/step - loss: 0.5372 - accuracy: 0.9215 - val_loss: nan - val_accuracy: 0.9296\n",
            "Epoch 4/10\n",
            "1130/1130 [==============================] - 265s 235ms/step - loss: 0.5310 - accuracy: 0.9221 - val_loss: nan - val_accuracy: 0.9298\n",
            "Epoch 5/10\n",
            "1130/1130 [==============================] - 265s 235ms/step - loss: 0.5252 - accuracy: 0.9225 - val_loss: nan - val_accuracy: 0.9295\n",
            "Epoch 6/10\n",
            "1130/1130 [==============================] - 265s 235ms/step - loss: 0.5208 - accuracy: 0.9228 - val_loss: nan - val_accuracy: 0.9299\n",
            "Epoch 7/10\n",
            "1130/1130 [==============================] - 265s 235ms/step - loss: 0.5167 - accuracy: 0.9230 - val_loss: nan - val_accuracy: 0.9300\n",
            "Epoch 8/10\n",
            "1130/1130 [==============================] - 265s 235ms/step - loss: 0.5123 - accuracy: 0.9233 - val_loss: nan - val_accuracy: 0.9300\n",
            "Epoch 9/10\n",
            "1130/1130 [==============================] - 265s 235ms/step - loss: 0.5069 - accuracy: 0.9239 - val_loss: nan - val_accuracy: 0.9305\n",
            "Epoch 10/10\n",
            "1130/1130 [==============================] - 265s 235ms/step - loss: 0.5016 - accuracy: 0.9242 - val_loss: nan - val_accuracy: 0.9306\n",
            "1/1 [==============================] - 0s 325ms/step\n",
            "bhí an a a an an an an an an an an an .                                                                                                                                                                                                               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "QDf1o66jVt7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_model.save('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/embedding')"
      ],
      "metadata": {
        "id": "SjrWreb9YndD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2f7bf3-1e2b-4ab9-a2d8-718e3f1ace99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "4PmmJzksVkCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "MeqQf4C3VvGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train encode/decode model\n",
        "\n",
        "tmp_x = pad(pre_source)\n",
        "tmp_x = tmp_x.reshape((-1, pre_target.shape[-2]))\n",
        "\n",
        "encodeco_model = encdec_model(\n",
        "    tmp_x.shape,\n",
        "    pre_source.shape[1],\n",
        "    len(source_token.word_index)+1,\n",
        "    len(target_token.word_index)+1)\n",
        "\n",
        "encodeco_model.fit(tmp_x, pre_target, batch_size=32, epochs=20, validation_split=0.2)\n",
        "\n",
        "print(logits_to_text(encodeco_model.predict(tmp_x[:1])[0], target_token))"
      ],
      "metadata": {
        "id": "J6Ey4oIlUb8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a568df92-6c01-49b6-e99a-f73b623f63c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a33b8fb01551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtmp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtmp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m encodeco_model = encdec_model(\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10434501 into shape (221)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "N2aT6vIEVwZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encodeco_model.save('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/encode')"
      ],
      "metadata": {
        "id": "KfNNIcajYp8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd"
      ],
      "metadata": {
        "id": "ZFg6b4juVkxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Embedding Bi-directional model\n",
        "\n",
        "tmp_X = pad(pre_source)\n",
        "model = model_final(tmp_X.shape,\n",
        "                    pre_target.shape[1],\n",
        "                    len(source_token.word_index)+1,\n",
        "                    len(target_token.word_index)+1)\n",
        "\n",
        "model.fit(tmp_X, pre_target, batch_size = 32, epochs = 17, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "i25NMGT6WGPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65499ddd-84b0-4de6-deb0-cd8bdf237ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "1130/1130 [==============================] - 471s 412ms/step - loss: 0.6875 - accuracy: 0.9180 - val_loss: 0.5706 - val_accuracy: 0.9284\n",
            "Epoch 2/17\n",
            "1130/1130 [==============================] - 466s 412ms/step - loss: 0.6538 - accuracy: 0.9200 - val_loss: 0.5681 - val_accuracy: 0.9287\n",
            "Epoch 3/17\n",
            "1130/1130 [==============================] - 466s 412ms/step - loss: 0.6552 - accuracy: 0.9203 - val_loss: 0.5678 - val_accuracy: 0.9294\n",
            "Epoch 4/17\n",
            "1130/1130 [==============================] - 467s 413ms/step - loss: 0.6493 - accuracy: 0.9211 - val_loss: 0.5636 - val_accuracy: 0.9303\n",
            "Epoch 5/17\n",
            "1130/1130 [==============================] - 467s 413ms/step - loss: 0.6433 - accuracy: 0.9219 - val_loss: 0.5591 - val_accuracy: 0.9317\n",
            "Epoch 6/17\n",
            "1130/1130 [==============================] - 468s 414ms/step - loss: 0.6371 - accuracy: 0.9228 - val_loss: 0.5566 - val_accuracy: 0.9319\n",
            "Epoch 7/17\n",
            "1130/1130 [==============================] - 467s 414ms/step - loss: 0.6282 - accuracy: 0.9236 - val_loss: 0.5605 - val_accuracy: 0.9315\n",
            "Epoch 8/17\n",
            "1130/1130 [==============================] - 467s 413ms/step - loss: 0.6201 - accuracy: 0.9243 - val_loss: 0.5970 - val_accuracy: 0.9174\n",
            "Epoch 9/17\n",
            "1130/1130 [==============================] - 466s 413ms/step - loss: 0.6120 - accuracy: 0.9250 - val_loss: 0.5286 - val_accuracy: 0.9340\n",
            "Epoch 10/17\n",
            "1130/1130 [==============================] - 466s 412ms/step - loss: 0.6095 - accuracy: 0.9252 - val_loss: 0.5262 - val_accuracy: 0.9341\n",
            "Epoch 11/17\n",
            "1130/1130 [==============================] - 465s 412ms/step - loss: 0.6028 - accuracy: 0.9257 - val_loss: 0.5152 - val_accuracy: 0.9349\n",
            "Epoch 12/17\n",
            "1130/1130 [==============================] - 465s 412ms/step - loss: 0.5985 - accuracy: 0.9261 - val_loss: 0.5155 - val_accuracy: 0.9349\n",
            "Epoch 13/17\n",
            "1130/1130 [==============================] - 465s 412ms/step - loss: 0.5956 - accuracy: 0.9264 - val_loss: 0.5126 - val_accuracy: 0.9349\n",
            "Epoch 14/17\n",
            "1130/1130 [==============================] - 465s 412ms/step - loss: 0.5905 - accuracy: 0.9268 - val_loss: 0.5319 - val_accuracy: 0.9289\n",
            "Epoch 15/17\n",
            "1130/1130 [==============================] - 466s 413ms/step - loss: 0.5818 - accuracy: 0.9273 - val_loss: 0.5062 - val_accuracy: 0.9340\n",
            "Epoch 16/17\n",
            "1130/1130 [==============================] - 465s 412ms/step - loss: 0.5761 - accuracy: 0.9277 - val_loss: 0.4955 - val_accuracy: 0.9364\n",
            "Epoch 17/17\n",
            "1130/1130 [==============================] - 464s 411ms/step - loss: 0.5720 - accuracy: 0.9281 - val_loss: 0.4949 - val_accuracy: 0.9356\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faeb3006ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/MyDrive/Colab_Notebooks/NLP/translation/bidi-encode')"
      ],
      "metadata": {
        "id": "J_A91zv8YtlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c218bec5-437e-4ebf-a11b-c886c4441ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    }
  ]
}